{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16237c6a",
   "metadata": {},
   "source": [
    "# 14. 트랜스포머로 만드는 대화형 챗봇"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f3f67",
   "metadata": {},
   "source": [
    "## 14-14. 프로젝트: 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25150470",
   "metadata": {},
   "source": [
    "#### 라이브러리 버전 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb09bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf22c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re   # 정규화할때 사용\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad89c1",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303adbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "# $ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbc7da",
   "metadata": {},
   "source": [
    "깃허브 주소 : https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c66683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data = pd.read_csv(os.getenv('HOME') + '/aiffel/transformer_chatbot/data/ChatbotData .csv')\n",
    "chat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20958b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SNS보면 나만 빼고 다 행복해보여</td>\n",
       "      <td>자랑하는 자리니까요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>가끔 궁금해</td>\n",
       "      <td>그 사람도 그럴 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>가끔 뭐하는지 궁금해</td>\n",
       "      <td>그 사람도 그럴 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>가끔은 혼자인게 좋다</td>\n",
       "      <td>혼자를 즐기세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>가난한 자의 설움</td>\n",
       "      <td>돈은 다시 들어올 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>가만 있어도 땀난다</td>\n",
       "      <td>땀을 식혀주세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>가상화폐 쫄딱 망함</td>\n",
       "      <td>어서 잊고 새출발 하세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>가스불 켜고 나갔어</td>\n",
       "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>가스불 켜놓고 나온거 같아</td>\n",
       "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>가스비 너무 많이 나왔다.</td>\n",
       "      <td>다음 달에는 더 절약해봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>가스비 비싼데 감기 걸리겠어</td>\n",
       "      <td>따뜻하게 사세요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>가스비 장난 아님</td>\n",
       "      <td>다음 달에는 더 절약해봐요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>가장 확실한 건 뭘까?</td>\n",
       "      <td>가장 확실한 시간은 오늘이에요. 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>가족 여행 가기로 했어</td>\n",
       "      <td>온 가족이 모두 마음에 드는 곳으로 가보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>가족 여행 고고</td>\n",
       "      <td>온 가족이 모두 마음에 드는 곳으로 가보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Q                                                 A  \\\n",
       "0                    12시 땡!                                        하루가 또 가네요.   \n",
       "1               1지망 학교 떨어졌어                                         위로해 드립니다.   \n",
       "2              3박4일 놀러가고 싶다                                       여행은 언제나 좋죠.   \n",
       "3           3박4일 정도 놀러가고 싶다                                       여행은 언제나 좋죠.   \n",
       "4                   PPL 심하네                                        눈살이 찌푸려지죠.   \n",
       "5                 SD카드 망가졌어                                다시 새로 사는 게 마음 편해요.   \n",
       "6                   SD카드 안돼                                다시 새로 사는 게 마음 편해요.   \n",
       "7            SNS 맞팔 왜 안하지ㅠㅠ                                  잘 모르고 있을 수도 있어요.   \n",
       "8   SNS 시간낭비인 거 아는데 매일 하는 중                                     시간을 정하고 해보세요.   \n",
       "9         SNS 시간낭비인데 자꾸 보게됨                                     시간을 정하고 해보세요.   \n",
       "10      SNS보면 나만 빼고 다 행복해보여                                       자랑하는 자리니까요.   \n",
       "11                   가끔 궁금해                                     그 사람도 그럴 거예요.   \n",
       "12              가끔 뭐하는지 궁금해                                     그 사람도 그럴 거예요.   \n",
       "13              가끔은 혼자인게 좋다                                         혼자를 즐기세요.   \n",
       "14                가난한 자의 설움                                    돈은 다시 들어올 거예요.   \n",
       "15               가만 있어도 땀난다                                         땀을 식혀주세요.   \n",
       "16               가상화폐 쫄딱 망함                                    어서 잊고 새출발 하세요.   \n",
       "17               가스불 켜고 나갔어                               빨리 집에 돌아가서 끄고 나오세요.   \n",
       "18           가스불 켜놓고 나온거 같아                               빨리 집에 돌아가서 끄고 나오세요.   \n",
       "19           가스비 너무 많이 나왔다.                                   다음 달에는 더 절약해봐요.   \n",
       "20          가스비 비싼데 감기 걸리겠어                                         따뜻하게 사세요!   \n",
       "21                가스비 장난 아님                                   다음 달에는 더 절약해봐요.   \n",
       "22             가장 확실한 건 뭘까?  가장 확실한 시간은 오늘이에요. 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요.   \n",
       "23             가족 여행 가기로 했어                         온 가족이 모두 마음에 드는 곳으로 가보세요.   \n",
       "24                 가족 여행 고고                         온 가족이 모두 마음에 드는 곳으로 가보세요.   \n",
       "\n",
       "    label  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  \n",
       "10      0  \n",
       "11      0  \n",
       "12      0  \n",
       "13      0  \n",
       "14      0  \n",
       "15      0  \n",
       "16      0  \n",
       "17      0  \n",
       "18      0  \n",
       "19      0  \n",
       "20      0  \n",
       "21      0  \n",
       "22      0  \n",
       "23      0  \n",
       "24      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc4030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bb152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "\n",
    "MAX_SAMPLES = 11823 \n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d58cf8",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97946a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^가-힣?.!,]+\", \" \", sentence)  # 한글 전처리\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "#     # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "#     sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "#     sentence = sentence.strip()\n",
    "    \n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab71ad",
   "metadata": {},
   "source": [
    "한글 정규식 https://doubly12f.tistory.com/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a78a6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "#     id2line = {}\n",
    "#     with open(path_to_movie_lines, errors='ignore') as file:\n",
    "#         lines = file.readlines()\n",
    "#     for line in lines:\n",
    "#         parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "#         id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "#     with open(path_to_movie_conversations, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "\n",
    "#     for line in lines:\n",
    "#         parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "#         conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(chat_data)):\n",
    "      # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "        inputs.append(preprocess_sentence(chat_data['Q'][i]))\n",
    "        outputs.append(preprocess_sentence(chat_data['A'][i]))\n",
    "\n",
    "        if len(inputs) >= MAX_SAMPLES:\n",
    "            return inputs, outputs\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c72c45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a420be79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf0bbf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 1112번째 질문 샘플: 다 필요없어\n",
      "전처리 후의 1112번째 답변 샘플: 모든 건 필요가 있어요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 1112번째 질문 샘플: {}'.format(questions[1111]))\n",
    "print('전처리 후의 1112번째 답변 샘플: {}'.format(answers[1111]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0099d9",
   "metadata": {},
   "source": [
    "## Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3c6796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SubwordTextEncoder vocab_size=8127>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17507255",
   "metadata": {},
   "source": [
    "이미 생성된 단어장의 번호와 겹치지 않도록 각각 단어장의 크기와 그보다 1이 큰 수를 번호로 부여한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "526b3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "455618f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8127]\n",
      "END_TOKEN의 번호 : [8128]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 부여된 정수를 출력\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e8d63",
   "metadata": {},
   "source": [
    "현재 단어장의 크기가 8,127(0번부터 8,126번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab8283b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8129\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101474c",
   "metadata": {},
   "source": [
    "각 단어장을 고유한 정수로 인코딩(Integer encoding) & 패딩(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd823b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5742, 612, 2481, 4148]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2352, 7481, 7, 6245, 97, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0120835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e0f4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "    return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54cdb83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8129\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13edd112",
   "metadata": {},
   "source": [
    "교사 강요(Teacher Forcing)\n",
    "\n",
    "테스트 과정에서 t 시점의 출력이 t+1 시점의 입력으로 사용되는 RNN모델을 훈련시길 때 사용하는 훈련기법\n",
    "\n",
    "훈련할때 교사 강요를 사용할 경우, 모델이 t 시점에서 예측한 값을 t+1ㅣ점에 입력으로 사용하지 않고, t 시점의 레이블 즉, 실제 알고있는 정답을 t+1 시점의 입력으로 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b473d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ac785",
   "metadata": {},
   "source": [
    "## Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867db914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "        \n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7774fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수 \n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af537fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티 헤드 어텐션 \n",
    "# 내부적으로 스케일드 닷 프로턱트 어텐션 함수를 호출한다\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        \n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션 함수\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,(batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a375a273",
   "metadata": {},
   "source": [
    "마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd4c92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 마스킹\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    #(batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00197c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e65cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 룩 어헤드 마스킹(다음단어 가리기)\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a8928ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66317d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5cee92",
   "metadata": {},
   "source": [
    "인코더\n",
    "\n",
    "셀프 어텐션 , 피드 포워드 신경망\n",
    "\n",
    "셀프 어텐션 : 멀테 헤드 어텐션으로 병렬로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b53b6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention\")({\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef8c905",
   "metadata": {},
   "source": [
    "인코더 층 쌓아 인코더 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0c32b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fc1a68",
   "metadata": {},
   "source": [
    "디코더\n",
    "\n",
    "세개의 서브층\n",
    "\n",
    "1. 셀프 어텐션\n",
    "\n",
    "2. 인코더-디코더 어텐션\n",
    "\n",
    "3. 피드 포워드 신경망\n",
    "\n",
    "셀프 어텐션, 인코더-디코더 어텐션은 스케일드 닷 프로턱트 어텐션을 멀티헤드 어텐션으로 병렬적으로 수행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44387b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "            'query': inputs,\n",
    "            'key': inputs,\n",
    "            'value': inputs,\n",
    "            'mask': look_ahead_mask\n",
    "        })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "            'query': attention1,\n",
    "            'key': enc_outputs,\n",
    "            'value': enc_outputs,\n",
    "            'mask': padding_mask\n",
    "        })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "        epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f23b64",
   "metadata": {},
   "source": [
    "디코더 층을 쌓아 디코더 만들기\n",
    "\n",
    "디코더 층은 임베딩 층과 포지셔널 인코딩을 연결하고 \n",
    "\n",
    "사용자가 원하는 만큼 디코더 층을 쌓아 트랜스포머의 디코더가 완성된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ba30e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "        shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49cb0cd",
   "metadata": {},
   "source": [
    "트랜스포머함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae771f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),\n",
    "        name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None),\n",
    "        name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918bf7a",
   "metadata": {},
   "source": [
    "모델 생성\n",
    "\n",
    "num_layers, d-Model, units 사용자가 정할 수 있는 하이퍼파라미터\n",
    "\n",
    "논문에서 num_layers 6 , d-Model 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f136715",
   "metadata": {},
   "source": [
    "NUM_LAYERS = 2 \n",
    "\n",
    "D_MODEL = 256 \n",
    "\n",
    "NUM_HEADS = 8 \n",
    "\n",
    "UNITS = 512 \n",
    "\n",
    "DROPOUT = 0.1\n",
    "\n",
    "Total params: 8,886,977\n",
    "\n",
    "e 10 의 결과는 좋지 못했다\n",
    "\n",
    "NUM_LAYERS = 6 \n",
    "\n",
    "D_MODEL = 512 \n",
    "\n",
    "NUM_HEADS = 8 \n",
    "\n",
    "UNITS = 512 \n",
    "\n",
    "DROPOUT = 0.1\n",
    "\n",
    "논문에서처럼 변경해주고 e 도 50을 해주니 좋은결과가 나오는걸 확인할 수 있었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d70b541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    13629952    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    19939840    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8129)   4170177     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 37,739,969\n",
      "Trainable params: 37,739,969\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 6 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a96f46",
   "metadata": {},
   "source": [
    "손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d77d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fda606",
   "metadata": {},
   "source": [
    "커스텀 된 학습률(learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dccccd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cd76d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d109c",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59886497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(\n",
    "                                        learning_rate, \n",
    "                                        beta_1=0.9, \n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9 )\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss=loss_function, \n",
    "              metrics=[accuracy])\n",
    "\n",
    "# es = EarlyStopping(monitor='val_loss', patience=3, verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071b267",
   "metadata": {},
   "source": [
    "훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e9c784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 58s 222ms/step - loss: 1.3436 - accuracy: 0.0224\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 1.0767 - accuracy: 0.0480\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.9809 - accuracy: 0.0510\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.9373 - accuracy: 0.0529\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 41s 222ms/step - loss: 0.9005 - accuracy: 0.0553\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 41s 222ms/step - loss: 0.8628 - accuracy: 0.0574\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.8208 - accuracy: 0.0597\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 41s 222ms/step - loss: 0.7704 - accuracy: 0.0630\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.7141 - accuracy: 0.0674\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.6530 - accuracy: 0.0730\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.5918 - accuracy: 0.0795\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.5315 - accuracy: 0.0868\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.4741 - accuracy: 0.0939\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.4233 - accuracy: 0.1005\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.3793 - accuracy: 0.1064\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.3430 - accuracy: 0.1113\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.3137 - accuracy: 0.1151\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.2929 - accuracy: 0.1177\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.2761 - accuracy: 0.1202\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.2649 - accuracy: 0.1217\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.2552 - accuracy: 0.1229\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.2460 - accuracy: 0.1242\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.2338 - accuracy: 0.1261\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.2182 - accuracy: 0.1287\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.2054 - accuracy: 0.1307\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1943 - accuracy: 0.1325\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1819 - accuracy: 0.1346\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1726 - accuracy: 0.1363\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1656 - accuracy: 0.1374\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.1567 - accuracy: 0.1388\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1497 - accuracy: 0.1398\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.1420 - accuracy: 0.1414\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1359 - accuracy: 0.1423\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1325 - accuracy: 0.1430\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.1256 - accuracy: 0.1444\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1198 - accuracy: 0.1454\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1163 - accuracy: 0.1459\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.1121 - accuracy: 0.1468\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.1076 - accuracy: 0.1479\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 41s 221ms/step - loss: 0.1045 - accuracy: 0.1483\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.1012 - accuracy: 0.1493\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0967 - accuracy: 0.1499\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0933 - accuracy: 0.1507\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0909 - accuracy: 0.1512\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0878 - accuracy: 0.1519\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0836 - accuracy: 0.1528\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0817 - accuracy: 0.1532\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0790 - accuracy: 0.1538\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0767 - accuracy: 0.1542\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 41s 220ms/step - loss: 0.0729 - accuracy: 0.1550\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "hist = model.fit(dataset, \n",
    "                 epochs=EPOCHS, \n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d84975",
   "metadata": {},
   "source": [
    "그래프를 통해 잘 수렴했는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab13d135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'], label='train')\n",
    "# plt.plot(hist.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0b94a",
   "metadata": {},
   "source": [
    "## Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6bd64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb1ae32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('Question : {}'.format(sentence))\n",
    "    print('Answer : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b74717",
   "metadata": {},
   "source": [
    "입력과 출력을 Question과 Answer로 표기하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ea0801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 안녕?\n",
      "Answer : 안녕하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'안녕하세요 .'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"안녕?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "144b903e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 배고파\n",
      "Answer : 뭐 좀 챙겨드세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'뭐 좀 챙겨드세요 .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"배고파\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d53d202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 오늘 점심 메뉴 추천해줘\n",
      "Answer : 된다면 도전해보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'된다면 도전해보세요 .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"오늘 점심 메뉴 추천해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "745a335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 너는 누구야?\n",
      "Answer : 저는 생각보다 많이 벌어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 생각보다 많이 벌어요 .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너는 누구야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a815d66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 흑기사 해주는 짝남.\n",
      "Answer : 설렜겠어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'설렜겠어요 .'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"흑기사 해주는 짝남.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0024db89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 흑ㅋ기 사 해주ㅋ는 짝남.\n",
      "Answer : 상처받은 마음 보듬어주고 싶네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'상처받은 마음 보듬어주고 싶네요 .'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"흑ㅋ기 사 해주ㅋ는 짝남.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f66231fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 흑기사ㅋ 해주는 ㅋㅋㅋ 짝ㅋ남\n",
      "Answer : 보험처리 하세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'보험처리 하세요 .'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"흑기사ㅋ 해주는 ㅋㅋㅋ 짝ㅋ남\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfc747fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 훔쳐보는 것도 눈치 보임.\n",
      "Answer : 사표를 써서 품에 품어 봅니다 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'사표를 써서 품에 품어 봅니다 .'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"훔쳐보는 것도 눈치 보임.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b183df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : 가장 확실한 건 뭘까?\n",
      "Answer : 가장 확실한 시간은 오늘이에요 . 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'가장 확실한 시간은 오늘이에요 . 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요 .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"가장 확실한 건 뭘까?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df007ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : ㅋㅋㅋㅋㅋㅋ\n",
      "Answer : 곧 방학이예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'곧 방학이예요 .'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"ㅋㅋㅋㅋㅋㅋ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25d4e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : abcdefg\n",
      "Answer : 곧 방학이예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'곧 방학이예요 .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"abcdefg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "007ae51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question : asdf안zxceㅋㅌㅊ치ㅏㅁ녕ㄴㅇㄹㅊ\n",
      "Answer : 아픔의 흔적 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'아픔의 흔적 .'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"asdf안zxceㅋㅌㅊ치ㅏㅁ녕ㄴㅇㄹㅊ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324e325",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ebfbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641992d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f340c491",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b624f65",
   "metadata": {},
   "source": [
    "- 이번 프로젝트에서 **어려웠던 점,**\n",
    "\n",
    "어텐션에 대해 학습하는것이 어려웠다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c8c92",
   "metadata": {},
   "source": [
    "- 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**.\n",
    "\n",
    "노드에서 학습했던 내용을 기반으로 트랜스포머 하이퍼파라미터를 줬었을때 결과가 그리 좋지 못했었다.\n",
    "\n",
    "논문처럼 num_layers 6 , d-Model 512으로 변경해주고 시도해보니\n",
    "\n",
    "거의 완벽하다 라고 생각이 들 수준의 결과가 나왔다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7c396",
   "metadata": {},
   "source": [
    "- 루브릭 평가 지표를 맞추기 위해 **시도한 것들**.\n",
    "\n",
    "한국어 전처리하는 과정을 거치고 트랜스포머 모델을 한국어 챗봇 모델학습을 진행하였다\n",
    "\n",
    "한국어로 답변하는 함수를 구현하고 한국어 입력문장 맥락에 맞는 한국어로 답변을 리턴하였다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c34ad69",
   "metadata": {},
   "source": [
    "- 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**.낌\n",
    "\n",
    "좀 더 다양한 한국어 전처리를 하지 못한것이 아쉽다"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "cb0c5df0",
   "metadata": {},
   "source": [
    "- **자기 다짐**\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b3c51d",
   "metadata": {},
   "source": [
    "전반적으로 좋은 결과가 나와서 좋았지만,\n",
    "\n",
    "위 사진처럼 원래 문장에서 글자 사이에 다른것이 포함될 경우 다른 결과가 나오는것을 확인했는데,\n",
    "\n",
    "이 부분을 전처리를 더 추가한다면 더 좋은 결과를 얻을 수 있지 않을까 하는 생각이 든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5004536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
